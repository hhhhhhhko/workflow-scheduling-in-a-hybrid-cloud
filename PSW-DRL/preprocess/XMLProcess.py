import networkx
import xml.dom.minidom
import random
import numpy as np
import re

#ä½¿ç”¨æœ‰å‘æ— ç¯å›¾(DAG)è¡¨ç¤ºä¸€ä¸ªå·¥ä½œæµ(workflow)æ¨¡å‹ï¼Œå³DAG=(V,E)ï¼Œå…¶ä¸­é¡¶ç‚¹Vè¡¨ç¤ºä¸€ç»„ä»»åŠ¡ï¼Œè¾¹Eè¡¨ç¤ºä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»
class DAG:
    def __init__(self, dag_args):
        '''
        file_name : .daxæ–‡ä»¶çš„åç§°
        num_of_vertex : DAGä¸­çš„ä»»åŠ¡æ•°
        vertex[i] : ç¬¬iä¸ªä»»åŠ¡
        edge[i][j] : ä»»åŠ¡iå’Œä»»åŠ¡jä¹‹é—´çš„è¾¹
        pred[i] : ä»»åŠ¡içš„å‰é©±èŠ‚ç‚¹
        succ[i] : ä»»åŠ¡içš„åç»§èŠ‚ç‚¹
        entry[i]=1 : åˆ¤æ–­æ˜¯å¦ä¸ºentryå…¥å£ä»»åŠ¡, 1ä¸ºæ˜¯,0ä¸ºå¦
        exit[i]=1 : åˆ¤æ–­æ˜¯å¦ä¸ºexitå‡ºå£ä»»åŠ¡, 1ä¸ºæ˜¯,0ä¸ºå¦
        ranku[i] : ä»»åŠ¡içš„rankuå€¼
        '''

        self.file_name = dag_args.file_name
        self.num_of_vertex = dag_args.num_of_vertex
        self.vertex = dag_args.vertex
        self.edge = dag_args.edge
        self.pred = dag_args.pred
        self.succ = dag_args.succ
        self.entry = dag_args.entry
        self.exit = dag_args.exit
        self.ranku = dag_args.ranku


    # è¯»å–.daxæ–‡ä»¶
    '''
    def read_file_dax(self):
        path = "./DAG/" + self.file_name + ".dax"  # æ–‡ä»¶è·¯å¾„
        file_dax = open(path, 'r') 
    '''
    
    # è¯»å–xmlæ–‡ä»¶ï¼Œè¿”å›æœ‰å‘æ— ç¯å›¾DAG
    def get_workflow(): 
        dom = xml.dom.minidom.parse('PSW-DRL\XML_Scientific_Workflow\CyberShake\CyberShake_30.xml')  # è¯»å–xmlæ–‡ä»¶
        root = dom.documentElement  # è·å–æ ¹èŠ‚ç‚¹
        G = networkx.DiGraph()  # åˆ›å»ºæœ‰å‘å›¾
        for child in root.childNodes:  # éå†å­èŠ‚ç‚¹  
            if child.nodeName == "child":  # è·å–å­èŠ‚ç‚¹çš„åç§°
                child_node = child.getAttribute("ref")  # è·å–å­èŠ‚ç‚¹çš„å±æ€§
                for parent in child.childNodes:  
                    if parent.nodeName == "parent":
                        parent_node = parent.getAttribute("ref")  # è·å–çˆ¶èŠ‚ç‚¹çš„å±æ€§
                        print("parent_{0} -> child_{1}".format(parent_node,child_node))
                        G.add_edge(parent_node,child_node)  # æœ‰å‘å›¾ä¸­æ·»åŠ è¾¹
        node_list = list(networkx.topological_sort(G))  # æ‹“æ‰‘æ’åº
        _map = {item:index+1 for index,item in enumerate(node_list)}  # æšä¸¾
        # print(_map)
        # G = networkx.relabel_nodes(G,_map)
        # print(list(G.nodes()))
        return G  # è¿”å›æœ‰å‘æ— ç¯å›¾

    # è¯»å–xmlæ–‡ä»¶ä¸­ä»»åŠ¡çš„å±æ€§
    '''
    def get_task_attr():
        dom = xml.dom.minidom.parse('PSW-DRL\DAG\CyberShake\CyberShake_30.xml')
        root = dom.documentElement  # è·å–æ ¹èŠ‚ç‚¹
        task_attr = {}  # ä»»åŠ¡å±æ€§
        for child in root.childNodes:  # éå†å­èŠ‚ç‚¹
            if child.nodeName == "child":  # è·å–å­èŠ‚ç‚¹çš„åç§°
    '''       
''' 
class XMLtoDAG():
     
    def __init__(self, file, n_task):
        self.xmlFile = file
        self.n_task = n_task
        self.DAG = np.zeros((self.n_task, self.n_task), dtype=int)

    # è·å–DAG
    def get_dag(self):
        # ä½¿ç”¨minidomè§£æå™¨æ‰“å¼€ XML æ–‡æ¡£
        domtree = xml.dom.minidom.parse(self.xmlFile)
        collection = domtree.documentElement
        childrens = collection.getElementsByTagName("child")

        for child in childrens:
            child_id = child.getAttribute('ref')
            child_id = int(child_id[2:])
            # print('Child: ', child_id)
            parents = child.getElementsByTagName('parent')
            for parent in parents:
                parent_id = parent.getAttribute('ref')
                parent_id = int(parent_id[2:])
                # print(parent_id)
                self.DAG[parent_id, child_id] = 1
        return self.DAG
     
    # è·å–ä»»åŠ¡çš„å‰é©±èŠ‚ç‚¹
    def get_precursor(self):
        precursor = []
        for i in range(self.n_task):
            temp = self.DAG[:, i]
            if np.sum(temp) == 0:
                precursor.append(i)
        return precursor
    
    # ä»»åŠ¡å…³ç³»
    def print_graph(self):
        print(self.DAG)
        for i in range(30):
            for j in range(30):
                if self.DAG[i, j] != 0:
                    print(i, ' -> ', j)
''' 

'''
ç”¨æ¥é¢„å¤„ç†XMLæ–‡ä»¶, è·å¾—å„ç±»å±æ€§å‚æ•°: ä»»åŠ¡é›†åˆã€ä¾èµ–å…³ç³»ã€ä»»åŠ¡æ•°é‡ã€ä»»åŠ¡æ‰§è¡Œæ—¶é—´ã€ä»»åŠ¡çš„å‰é©±èŠ‚ç‚¹ã€
ä»»åŠ¡çš„åç»§èŠ‚ç‚¹ã€ä»»åŠ¡çš„å…¥å£èŠ‚ç‚¹ã€ä»»åŠ¡çš„å‡ºå£èŠ‚ç‚¹ã€ä»»åŠ¡çš„rankuå€¼
'''

from xml.etree.ElementTree import ElementTree
import numpy as np
import re, math
import xml.dom.minidom
from random import choice

# å¤„ç†ç§‘å­¦å·¥ä½œæµXMLæ–‡ä»¶
class XMLtoDAG():
    '''
    adag_tag = "{http://pegasus.isi.edu/schema/dax-3.6.xsd}adag" # <xs:element name="adag">
    job_tag = "{http://pegasus.isi.edu/schema/dax-3.6.xsd}job"  # <xs:element name="job">
    child_tag = "{http://pegasus.isi.edu/schema/dax-3.6.xsd}child"  # <xs:element name="child" minOccurs="0" maxOccurs="unbounded">
    parent_tag = "{http://pegasus.isi.edu/schema/dax-3.6.xsd}parent"  # <xs:element name="parent">
    uses_tag = "{http://pegasus.isi.edu/schema/dax-3.6.xsd}uses"  # <xs:element name="uses" type="JobUsesType" minOccurs="0" maxOccurs="unbounded"/>
    '''
    
    adag_tag = "{http://pegasus.isi.edu/schema/DAX}adag"
    job_tag = "{http://pegasus.isi.edu/schema/DAX}job"
    child_tag = "{http://pegasus.isi.edu/schema/DAX}child"
    parent_tag = "{http://pegasus.isi.edu/schema/DAX}parent"
    uses_tag = "{http://pegasus.isi.edu/schema/DAX}uses"
    

    def __init__(self, file):
        self.xmlFile = file
        self.n_job = int(re.compile(r'\d+').findall(file)[0])
        # self.DAG = np.zeros((self.n_job, self.n_job), dtype=int)  # å·¥ä½œæµçš„ç»“æ„ï¼Œè¡¨ç¤ºä¸ºä¸€ä¸ªç›¸é‚»çš„çŸ©é˜µ
        self.DAG = self.get_dag()  # å·¥ä½œæµçš„ç»“æ„ï¼Œè¡¨ç¤ºä¸ºä¸€ä¸ªç›¸é‚»çš„çŸ©é˜µ
        self.edge_num = self.get_edge_num()  # å·¥ä½œæµçš„è¾¹çš„æ•°é‡
        self.edges = self.get_edge_data()  # å·¥ä½œæµçš„è¾¹é›†åˆ(æ•°æ®å¤§å°)
        self.jobType = np.zeros((self.n_job), dtype=int)  # å·¥ä½œæµä¸­çš„ä»»åŠ¡ç±»å‹
        # è¦è¡¥å¾ˆå¤šå±æ€§ğŸ‘‡
        #for i in range(self.n_job):
        # self.job = self.jobs()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡é›†åˆ
        #self.runtime = np.zeros((self.n_job), dtype=int)  # å·¥ä½œæµä¸­çš„ä»»åŠ¡æ‰§è¡Œæ—¶é—´
        self.runtime = self.get_runtime()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡æ‰§è¡Œæ—¶é—´
        self.inputfilesize = self.get_inputfilesize()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„è¾“å…¥æ–‡ä»¶å¤§å°
        self.outputfilesize = self.get_outputfilesize()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„è¾“å‡ºæ–‡ä»¶å¤§å°
        self.privacy_security_level = self.get_privacy_security_level()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„éšç§å®‰å…¨çº§åˆ«
        self.precursor = self.get_precursor()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„å‰é©±èŠ‚ç‚¹
        self.successor = self.get_successor()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„åç»§èŠ‚ç‚¹
        self.entry = self.find_entry()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„å…¥å£èŠ‚ç‚¹
        self.exit = self.find_exit()  # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„å‡ºå£èŠ‚ç‚¹
        #self.ranku = np.zeros(self.n_job) # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„rankuå€¼
        #self.rankup = self.get_ranku() # å·¥ä½œæµä¸­çš„ä»»åŠ¡çš„rankupå€¼
        # cybershake_30çš„rankuğŸ‘‡
        #self.ranku = [0.06, 0.08, 99.11686, 23.25396, 0.97242, 43.42936, 1.35242, 32.19343, 0.99242, 50.24499, 1.02242, 38.542829999999995, 1.43242, 213.11966, 56.7703, 1.39242, 45.30769, 0.75242, 62.80325, 1.0324200000000001, 30.14001, 0.73242, 38.95841, 1.60242, 51.52214, 1.41242, 41.42794, 1.37242, 40.214389999999995, 0.77242]
        #self.ranku = np.zeros(self.n_job)
        self.jobs = self.jobs() # å·¥ä½œæµä¸­çš„ä»»åŠ¡é›†åˆ
        
 
        

    # ä½¿ç”¨minidomè§£é‡Šå™¨è·å–å·¥ä½œæµçš„DAG
    def get_dag(self): 
        domtree = xml.dom.minidom.parse(self.xmlFile)
        collection = domtree.documentElement
        childrens = collection.getElementsByTagName("child")
        
        '''
        ç¤ºä¾‹ï¼š
        <child ref="ID00000">
            <parent ref="ID00021"/>
            <parent ref="ID00012"/>
            <parent ref="ID00023"/>
            <parent ref="ID00010"/>
            <parent ref="ID00025"/>
            <parent ref="ID00006"/>
            <parent ref="ID00017"/>
            <parent ref="ID00027"/>
            <parent ref="ID00004"/>
            <parent ref="ID00015"/>
            <parent ref="ID00029"/>
            <parent ref="ID00008"/>
            <parent ref="ID00019"/>
        </child>
        '''
        DAG = np.zeros((self.n_job, self.n_job))
        for child in childrens:
            child_id = child.getAttribute('ref') # child ref="ID00000"
            child_id = int(child_id[2:])  # ref ="00000" 
            # print('Child: ', child_id)
            parents = child.getElementsByTagName('parent') # éå†æ¯ä¸ªå­èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹
            for parent in parents:
                parent_id = parent.getAttribute('ref') # parent ref="ID00021"
                parent_id = int(parent_id[2:])  # ref ="00021"
                # print(parent_id)
                DAG[parent_id, child_id] = 1
        return DAG # è¿”å›å·¥ä½œæµçš„DAG(çŸ©é˜µå½¢å¼ï¼Œæœ‰ä¾èµ–å…³ç³»çš„ä¸º1ï¼Œæ— ä¾èµ–å…³ç³»çš„ä¸º0)

    # è·å–å·¥ä½œæµçš„å‰é©±èŠ‚ç‚¹é›†åˆ
    '''
    def get_precursor(self):    
        precursor = []
        for i in range(self.n_job):
            temp = self.DAG[:, i] # å–åˆ—(æ¯ä¸ªä»»åŠ¡çš„åˆ—å‘é‡ä¸ºå…¶å¯¹åº”ä¾èµ–å…³ç³»)
            if np.sum(temp) == 0:  # np.sum()çŸ©é˜µæ±‚å’Œ
                precursor.append(i)
        return precursor
    '''
    def get_precursor(self): 
        precursor = [ [] for i in range(self.n_job) ]
        dag = self.get_dag()
        for in_node in range(self.n_job):
            for out_node in range(self.n_job):
                if(dag[in_node][out_node] == 1):
                    precursor[out_node].append(in_node)
        return precursor

    # è·å–å·¥ä½œæµçš„åç»§èŠ‚ç‚¹é›†åˆ
    '''
    def get_successor(self):    
        successor = []
        for i in range(self.n_job):
            temp = self.DAG[i, :]  # å–è¡Œ
            if np.sum(temp) == 0:
                successor.append(i)
        return successor
    '''
    def get_successor(self):    
        successor = [ [] for i in range(self.n_job) ]
        dag = self.get_dag()
        for in_node in range(self.n_job):
            for out_node in range(self.n_job):
                if(dag[in_node][out_node] != 0):
                    successor[in_node].append(out_node)
        return successor

    # è·å–è¾¹(ä¾èµ–å…³ç³»)çš„é›†åˆ
    def print_graph(self):  
        # print(self.DAG)
        '''
        ç¤ºä¾‹ï¼š[(2, 3), (2, 5), (2, 7), (2, 9), (2, 11), (3, 1), (3, 4), (4, 0), (5, 1), (5, 6), 
        (6, 0), (7, 1), (7, 8), (8, 0), (9, 1), (9, 10), (10, 0), (11, 1), (11, 12), (12, 0), 
        (13, 14), (13, 16), (13, 18), (13, 20), (13, 22), (13, 24), (13, 26), (13, 28), (14, 1),
          (14, 15), (15, 0), (16, 1), (16, 17), (17, 0), (18, 1), (18, 19), (19, 0), (20, 1), 
          (20, 21), (21, 0), (22, 1), (22, 23), (23, 0), (24, 1), (24, 25), (25, 0), (26, 1), 
          (26, 27), (27, 0), (28, 1), (28, 29), (29, 0)]
        '''
        edges = []
        for i in range(self.n_job):
            for j in range(self.n_job):
                if self.DAG[i, j] != 0:
                    # print(i, ' -> ', j)
                    edge = (i, j)
                    edges.append(edge)
        # print(edges)
        return edges
    
    # è·å–ä¼ è¾“æ•°æ®(å¯¹åº”è¾¹)å¤§å°(å•ä½B)
    def get_edge_data(self):
        job_1 = [row for row in self.jobs() if row['id'] == 0]
        if job_1[0]['namespace'] == 'CyberShake':
            with open('PSW-DRL\XML_Scientific_Workflow\CyberShake\CyberShake_throughput.txt', 'r') as file: # # æ‰“å¼€æ–‡ä»¶
                text = file.read() # # è¯»å–æ–‡ä»¶å†…å®¹
            groups = text.split('\n\n') # åˆ©ç”¨ç©ºè¡Œå°†è¿ç»­çš„æ•°å­—åˆ†ç»„
            number_arrays = [] # åˆ›å»ºå­˜å‚¨æ•°å­—ç»„çš„åˆ—è¡¨
            edges = np.zeros((self.n_job, self.n_job))
            # éå†æ¯ä¸ªåˆ†ç»„ï¼Œå°†æ•°å­—å­˜å‚¨åˆ°æ•°ç»„ä¸­
            for group in groups:
                numbers = group.strip().split(',')
                number_array = [int(num) for num in numbers]
                number_arrays.append(number_array)
            if self.n_job == 30:
                edge = number_arrays[0]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1         
                return edges
            elif self.n_job == 50:
                edge = number_arrays[1]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 100:
                edge = number_arrays[2]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 1000:
                edge = number_arrays[3]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
        
        elif job_1[0]['namespace'] == 'Genome':
            with open('PSW-DRL\XML_Scientific_Workflow\Epigenomics\Epigenomics_throughput.txt', 'r') as file: # # æ‰“å¼€æ–‡ä»¶
                text = file.read() # # è¯»å–æ–‡ä»¶å†…å®¹
            groups = text.split('\n\n') # åˆ©ç”¨ç©ºè¡Œå°†è¿ç»­çš„æ•°å­—åˆ†ç»„
            number_arrays = [] # åˆ›å»ºå­˜å‚¨æ•°å­—ç»„çš„åˆ—è¡¨
            edges = np.zeros((self.n_job, self.n_job))
            # éå†æ¯ä¸ªåˆ†ç»„ï¼Œå°†æ•°å­—å­˜å‚¨åˆ°æ•°ç»„ä¸­
            for group in groups:
                numbers = group.strip().split(',')
                number_array = [int(num) for num in numbers]
                number_arrays.append(number_array)
            if self.n_job == 24:
                edge = number_arrays[0]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 47:
                edge = number_arrays[1]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 100:
                edge = number_arrays[2]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 997:
                edge = number_arrays[3]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            
        elif job_1[0]['namespace'] == 'LIGO':
            with open('PSW-DRL\XML_Scientific_Workflow\LIGO\Inspiral_throughput.txt', 'r') as file:
                text = file.read()
            groups = text.split('\n\n')
            number_arrays = [] 
            edges = np.zeros((self.n_job, self.n_job))
            for group in groups:
                numbers = group.strip().split(',')
                number_array = [int(num) for num in numbers]
                number_arrays.append(number_array)
            if self.n_job == 30:
                edge = number_arrays[0]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 50:
                edge = number_arrays[1]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 100:
                edge = number_arrays[2]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 1000:
                edge = number_arrays[3]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
        
        elif job_1[0]['namespace'] == 'Montage':
            with open('PSW-DRL\XML_Scientific_Workflow\Montage\Montage_throughput.txt', 'r') as file:
                text = file.read()
            groups = text.split('\n\n')
            number_arrays = [] 
            edges = np.zeros((self.n_job, self.n_job))
            for group in groups:
                numbers = group.strip().split(',')
                number_array = [int(num) for num in numbers]
                number_arrays.append(number_array)
            if self.n_job == 25:
                edge = number_arrays[0]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 50:
                edge = number_arrays[1]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 100:
                edge = number_arrays[2]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 1000:
                edge = number_arrays[3]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            
        elif job_1[0]['namespace'] == 'SIPHT':
            with open('PSW-DRL\XML_Scientific_Workflow\SIPHT\Sipht_throughput.txt', 'r') as file:
                text = file.read()
            groups = text.split('\n\n')
            number_arrays = [] 
            edges = np.zeros((self.n_job, self.n_job))
            for group in groups:
                numbers = group.strip().split(',')
                number_array = [int(num) for num in numbers]
                number_arrays.append(number_array)
            if self.n_job == 29:
                edge = number_arrays[0]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 58:
                edge = number_arrays[1]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 97:
                edge = number_arrays[2]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
            elif self.n_job == 968:
                edge = number_arrays[3]
                count = 0
                for i in range(self.n_job):
                    for j in range(self.n_job):
                        if self.DAG[i, j] != 0:
                            edges[i, j] = edge[count]
                            count += 1 
                return edges
        '''
        edges = np.zeros((self.n_job, self.n_job))
        for i in range(self.n_job):
            for j in range(self.n_job):
                if self.DAG[i, j] != 0:
                    edges[i][j] = random.randrange(100,30000)
        return edges
        '''

    # è·å–è¾¹çš„æ•°é‡
    def get_edge_num(self):
        edges_num = 0
        for i in range(self.n_job):
            for j in range(self.n_job):
                if self.DAG[i, j] != 0:
                    edges_num += 1
        return edges_num

    # â­å·¥ä½œæµä¸­çš„ä»»åŠ¡é›†åˆ
    def jobs(self):
        """ä»»åŠ¡å±æ€§: id, name(task type), namespace(workflow), runtime, size(file)
        id : ä»»åŠ¡çš„ç¼–å·
        namespace : ä»»åŠ¡æ‰€å±å·¥ä½œæµ
        name : ä»»åŠ¡ç±»å‹
        runtime : ä»»åŠ¡é•¿åº¦
        file : ä»»åŠ¡çš„è¾“å…¥è¾“å‡ºæ–‡ä»¶, sizeä¸ºæ–‡ä»¶å¤§å°, linkå±æ€§è¡¨ç¤ºæ–‡ä»¶çš„ç§ç±»(inputè¾“å…¥æ–‡ä»¶æˆ–outputè¾“å‡ºæ–‡ä»¶)
        """

        tree = ElementTree(file=self.xmlFile)
        root = tree.getroot()
        simple_jobs = []
        pattern = re.compile(r'\+?[1-9][0-9]*$|0$')    # åŒ¹é…ç¬¬ä¸€ä¸ªä¸ä¸º0çš„æ•°å­—æˆ–è€…ä»¥0ç»“å°¾çš„æ•°å­—
        imagetypes = [200*1024*1024, 400*1024*1024, 1000*1024*1024, 2000*1024*1024]             # é•œåƒæ–‡ä»¶çš„å¤§å°ï¼Œ unit: *B
        for job in root.iter(tag=self.job_tag):
            input_size = []
            # print(len(job.findall(self.uses_tag)))
            for use in job.findall(self.uses_tag):
                if use.get('link')=='input':
                    use_input_file_size = int(use.get('size'))    # the usage files' size (unit: B)
                    # input_speed.append(round(use_file_size/(10*1024*1024),6))    # Network I/O bandwidth=10M/s
                    input_size.append(use_input_file_size)
                if use.get('link')=='output':
                    output_size = int(use.get('size'))
    
            Job_Privacy_Factor = 0.5

            simple_job = {'id': int(pattern.findall(job.attrib['id'])[0]), 
                            'name': job.attrib['name'], 
                            'namespace': job.attrib['namespace'],
                            'runtime': float(job.attrib['runtime']),    
                            'inputfilesize': sum(input_size),    # the total size of a job:  * B
                            'outputfilesize': output_size,      # the output sie of a job: *B
                            'imagesize': choice(imagetypes),   # the image size of the containerized task
                            # åŠ å…¥éšç§å’Œå®‰å…¨å‚æ•°ï¼Œéšæœºå–å€¼ï¼ˆæ ¹æ®åˆ†çº§ï¼‰
                            # åˆ¤æ–­æ˜¯å¦ä¸ºå…¥å£/å‡ºå£èŠ‚ç‚¹
                            'privacy_security_level': np.random.choice([1,2,3], p=[Job_Privacy_Factor,(1-Job_Privacy_Factor)/2, (1-Job_Privacy_Factor)/2])
                            #'privacy_security_level': random.randint(1,3),    # éšç§å®‰å…¨æ¨¡å‹ç­‰çº§
                            
                          }
            simple_jobs.append(simple_job)
        '''
        ç¤ºä¾‹ï¼š
        [{'id': 0, 'name': 'ZipPSA', 'namespace': 'CyberShake', 'runtime': 0.06, 'inputfilesize': 2808, 'outputfilesize': 172, 'imagesize': 2097152000}, 
        {'id': 1, 'name': 'ZipSeis', 'namespace': 'CyberShake', 'runtime': 0.08, 'inputfilesize': 312000, 'outputfilesize': 18657, 'imagesize': 1048576000},
        '''
        return simple_jobs
    
    # æ ¹æ®ä»»åŠ¡çš„ç¼–å·IDè¿”å›ä»»åŠ¡å±æ€§
    def get_node(self, id):
        for job in self.jobs():
            # print(job)
            if id==job['id']:
                return job
            
    # å·¥ä½œæµä¸­çš„ä»»åŠ¡ç±»å‹çš„é›†åˆ
    def types(self):  
        types = []
        res = []
        for job in self.jobs(): 
            types.append(job['name'])
        for i, type in enumerate({}.fromkeys(types).keys()):
            res.append(type)
        for i, type in enumerate(types):
            self.jobType[i]=res.index(type)
            # print(self.taskType[i])
        return res, self.jobType
    
    # å„ç±»å‹ä»»åŠ¡çš„runtime(ä»»åŠ¡é•¿åº¦)é›†åˆ
    def typeRTimeDicts(self, types, jobs):  
        typeRTimeDict = {}
        for typ in types:
            lst = []
            for job in jobs:
                if job['name'] == typ:
                    lst.append(job['runtime'])
            print(typ, lst)
            typeRTimeDict[typ] = lst
        return typeRTimeDict
    
    # å„ç±»å‹ä»»åŠ¡çš„transfer timeé›†åˆ
    def typeTTimeDicts(self, types, jobs):  # the set of transfer time for each type of jobs
        typTTimeDict = {}
        for typ in types:
            lst = []
            for job in jobs:
                if job['name'] == typ:
                    lst.append(job['transtime'])
            typTTimeDict[typ] = lst
        return typTTimeDict
    
    # é€šä¿¡æ—¶é—´äºŒç»´çŸ©é˜µï¼ˆå³edgeï¼‰
    def transtime(self):
        transtime = np.zeros((self.n_job, self.n_job))
        for i in range(self.n_job):
            for j in range(self.n_job):
                if self.DAG[i, j] != 0:
                    #transtime[i, j] = self.get_node(i)['transtime']
                    node = self.get_node(i)
                    # transtime[i, j] = [job['transtime'] for job in self.jobs() if job['id'] == node][0]
                    transtime[i, j] = 0.2
        return transtime

    # å¯»æ‰¾å…¥å£èŠ‚ç‚¹
    def find_entry(self):
        entry = [0] * self.n_job
        precursor = self.get_precursor()
        for i in range(self.n_job):
            if(len(precursor[i]) == 0):
                    entry[i] = 1
        return entry

    # å¯»æ‰¾å‡ºå£èŠ‚ç‚¹
    def find_exit(self):
        exit = [0] * self.n_job
        successor = self.get_successor()
        for i in range(self.n_job):
            if(len(successor[i]) == 0):
                    exit[i] = 1
        return exit

    # æ·»åŠ è™šæ‹Ÿå…¥å£èŠ‚ç‚¹
    def add_virtual_entry(self):
    #def add_virtual_entry(self,jobs):
        virtual_entry = {'id': -1, 'name': 'virtual_entry', 'namespace': 'virtual_entry', 'runtime': 0, 'inputfilesize': 0, 'outputfilesize': 0, 'imagesize': 0}
        self.jobs.insert(0, virtual_entry)
        self.precursor.insert(0, [])
        self.successor.insert(0, [])
        for i in range(self.n_job):
            # å¦‚æœæ­¤èŠ‚ç‚¹æ²¡æœ‰å‰é©±èŠ‚ç‚¹åˆ™è®¾ç½®è™šæ‹Ÿå…¥å£ä¸ºå…¶å‰é©±èŠ‚ç‚¹
            if(self.entry[i] == 1):
                self.precursor[i+1].append(virtual_entry['id'])
                self.successor[0].append(i)
            # è¿˜éœ€è¦åŠ å…¥input/outputæ–‡ä»¶çš„å¤§å°(æ·»åŠ è‡³è¿æ¥è™šæ‹Ÿå…¥å£/å‡ºå£çš„èŠ‚ç‚¹)
        #self.jobs().append(virtual_entry)

    # æ·»åŠ è™šæ‹Ÿå‡ºå£èŠ‚ç‚¹
    def add_virtual_exit(self):
        virtual_exit = {'id': -2, 'name': 'virtual_entry', 'namespace': 'virtual_entry', 'runtime': 0, 'inputfilesize': 0, 'outputfilesize': 0, 'imagesize': 0}
        self.jobs.append(virtual_exit)
        self.precursor.append([])
        self.successor.append([])
        for i in range(self.n_job):
            # å¦‚æœæ­¤èŠ‚ç‚¹æ²¡æœ‰åç»§èŠ‚ç‚¹åˆ™è®¾ç½®è™šæ‹Ÿå‡ºå£ä¸ºå…¶åç»§èŠ‚ç‚¹
            if(self.exit[i] == 1):
                self.successor[i+1].append(virtual_exit['id'])
                self.precursor[self.n_job + 1].append(i)
            # è¿˜éœ€è¦åŠ å…¥input/outputæ–‡ä»¶çš„å¤§å°(æ·»åŠ è‡³è¿æ¥è™šæ‹Ÿå…¥å£/å‡ºå£çš„èŠ‚ç‚¹)

    # è¿”å›è™šæ‹Ÿå…¥å£èŠ‚ç‚¹ä»»åŠ¡çš„ç¼–å·  (å°±æ˜¯-1å§ï¼‰
    def virtual_entry_index(self):
        for job in self.jobs():
            if job['name'] == 'virtual_entry':
                index = job['id']
                #return job['id']
                return index
    
    # è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹é—´çš„ä¼ è¾“æ—¶é—´(çŸ©é˜µå½¢å¼æ¯”è¾ƒå¥½)

    # è®¡ç®—rankuçš„å€¼
    def ranku_calc(self, n):
        ranku = np.zeros(self.n_job)
        if(self.exit[n] == 1): # è‹¥ä¸ºå‡ºå£exitèŠ‚ç‚¹
            ranku[n] = self.runtime[n] 
            #self.ranku[n] = [job['runtime'] for job in self.jobs() if job['id'] == n][0]
            #self.ranku[n] = self.jobs()[self.jobs()['id'] == n]['runtime']   # å‡ºå£exitèŠ‚ç‚¹çš„rankuå€¼ä¸ºè¯¥ä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´
        else: # è‹¥ä¸ºéå‡ºå£exitèŠ‚ç‚¹
            for succ_n in self.successor[n]: # éå†è¯¥ä»»åŠ¡çš„åç»§successorèŠ‚ç‚¹
                if(ranku[succ_n] != 0): # å¦‚æœrankuå€¼å·²ç»è¢«è®¡ç®—è¿‡ï¼Œåˆ™è·³è¿‡
                    continue
                self.ranku_calc(succ_n) # é€’å½’è®¡ç®—åç»§successorèŠ‚ç‚¹çš„rankuå€¼
        
        # åœ¨åç»§èŠ‚ç‚¹ä¸­æ‰¾åˆ°å…·æœ‰æœ€å¤§çš„ "å½“å‰èŠ‚ç‚¹nåˆ°åç»§èŠ‚ç‚¹succ_nçš„é€šä¿¡æ—¶é—´+åç»§èŠ‚ç‚¹succ_nçš„rankuå€¼"çš„èŠ‚ç‚¹å¹¶ä¿ç•™æœ€å¤§å€¼ã€‚
        max_value = 0
        for succ_n in self.successor[n]:
            tmp = (self.edges[n][succ_n] / 100000) + ranku[succ_n]  # å¸¦å®½10MB/s
            if(tmp > max_value):
                max_value = tmp
        ranku[n] = self.runtime[n]  + max_value
        #self.ranku[n] = [job['runtime'] for job in self.jobs() if job['id'] == n][0] + max_value # è®¡ç®—å½“å‰èŠ‚ç‚¹nçš„rankuå€¼ï¼Œä¸ºè¯¥ä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´+max_value
        return ranku[n]

    # è·å–rankuå€¼
    def get_ranku(self):
        rankup = np.zeros(self.n_job)
        for i in range(self.n_job):
            rankup[i] = self.ranku_calc(i)
        return rankup

    # ç”¨æ¥è¿”å›å‚æ•°ï¼Œåé¢æ¨¡å‹éœ€è¦ä»€ä¹ˆå°±è¿”å›ä»€ä¹ˆ
    def dag(self):
        n_job = self.n_job
        runtime = [row['runtime'] for row in self.jobs()]
        transtime = self.transtime()
        precursor = self.get_precursor()
        successor = self.get_successor()
        entry = self.find_entry()
        exit = self.find_exit()
        
        return n_job, runtime, transtime, precursor, successor, entry, exit

    # è¿”å›ä»»åŠ¡çš„runtime
    def get_runtime(self):
        runtime = [row['runtime'] for row in self.jobs()]
        return runtime
    
    # è¿”å›ä»»åŠ¡çš„privacy_security_level
    def get_privacy_security_level(self):
        privacy_security_level = [row['privacy_security_level'] for row in self.jobs()]
        return privacy_security_level

    # è¿”å›ä»»åŠ¡çš„inputfilesize
    def get_inputfilesize(self):
        inputfilesize = [row['inputfilesize'] for row in self.jobs()]
        return inputfilesize
    
    # è¿”å›ä»»åŠ¡çš„outputfilesize
    def get_outputfilesize(self):
        outputfilesize = [row['outputfilesize'] for row in self.jobs()]
        return outputfilesize